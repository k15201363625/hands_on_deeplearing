{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hands-on implementation of cnn with numpy--------fullyconnected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fc layer \n",
    "$$FullyConnected\\ layer = Flatten\\ layer + perceptron\\ layer$$\n",
    "\n",
    "> NOTE:fc layer 已经可以通过**global_average_pooling**实现代替\n",
    "所以直接将每一个channel的feature map全局池化降维到一个点得到一个channels长度的列向量，再应用MLP进行维度变换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(object):\n",
    "    def __init__(self,shape,output_size):\n",
    "        self.input_shape = shape\n",
    "        self.batch_size = shape[0]\n",
    "        self.output_shape = [self.batch_size,output_size]\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        num = 1\n",
    "        for i in shape[1:]:\n",
    "            num *= i\n",
    "        weight_scaler = np.sqrt(num/2)\n",
    "        self.weights = np.random.randn(num,output_size)/weight_scaler\n",
    "        self.bias = np.random.randn(output_size)/weight_scaler\n",
    "        \n",
    "        self.w_grad = np.zeros(self.weights.shape)\n",
    "        self.b_grad = np.zeros(self.bias.shape)\n",
    "    def forward_propagate(self,x):\n",
    "        self.x = x.reshape([self.batch_size,-1])\n",
    "        return np.dot(self.x,self.weights) + self.bias\n",
    "    def gradient_cal(self,delta):\n",
    "        # 对于w_grad 对于batch中的每一个sample进行反向传播之后sum\n",
    "        for i in range(delta.shape[0]):\n",
    "            x_i = self.x[i][:,np.newaxis]\n",
    "            delta_i = delta[i][:,np.newaxis].T\n",
    "            self.w_grad += np.dot(x_i,delta_i)\n",
    "            self.b_grad += np.reshape(delta_i,self.bias.shape)\n",
    "        # 如果对于整体进行快速处理 可以使用以下code\n",
    "        delta_transposed = np.transpose(delta[...,np.newaxis],[0,2,1])\n",
    "        x_extend = self.x[...,np.newaxis]\n",
    "        # w_grad_everybatch = np.dot(x_extend,delta_transposed) # 默认忽略第一维度 进行运算\n",
    "        w_grad_everybatch = np.matmul(x_extend,delta_transposed) # 默认忽略第一维度 进行运算\n",
    "        # print(x_extend.shape,delta_transposed.shape,w_grad_everybatch.shape)\n",
    "        w_grad = np.sum(w_grad_everybatch,axis=0)\n",
    "        b_grad = np.sum(delta,axis=0)\n",
    "        # demo fpr consistence of calculation\n",
    "        print(w_grad-self.w_grad)\n",
    "        print(b_grad-self.b_grad)\n",
    "        \n",
    "        # input_delta\n",
    "        input_delta = np.dot(delta,self.weights.T).reshape(self.input_shape)\n",
    "        return input_delta\n",
    "    def backward_propagate(self,delta,learning_rate=1e-5,weight_decay=1e-4):\n",
    "        # zero gradient\n",
    "        self.w_grad = np.zeros(self.weights.shape)\n",
    "        self.b_grad = np.zeros(self.bias.shape)\n",
    "        \n",
    "        input_delta = self.gradient_cal(delta)\n",
    "        # use weight decay -> l2 regularization\n",
    "        self.weights *= (1-weight_decay)\n",
    "        self.bias *= (1-weight_decay)\n",
    "        self.weights -= learning_rate * self.w_grad\n",
    "        self.bias -= learning_rate * self.b_grad\n",
    "        return input_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "# 对于可是迭代对象进行某个累积函数操作\n",
    "reduce(lambda x,y:x*y,[1,2,5,36,4]) \n",
    "# 可以替代上面的循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "[0. 0.]\n",
      "(2, 2, 2) (2, 2) (4, 2) (2,)\n",
      "[[-1.51977166 -5.2736936 ]\n",
      " [-1.51977166 -5.2736936 ]]\n",
      "[[ 4.  2.]\n",
      " [ 8.  4.]\n",
      " [12.  6.]\n",
      " [16.  8.]]\n",
      "[4. 2.]\n",
      "[[-0.21713341  0.9877772 ]\n",
      " [-1.12031796 -1.15371593]\n",
      " [-0.24995073 -1.6138691 ]\n",
      " [ 0.43325534  0.07739696]]\n",
      "[-0.04625952  0.57788791]\n"
     ]
    }
   ],
   "source": [
    "# test code\n",
    "if __name__ == \"__main__\":\n",
    "    img = np.array([[[1,2],[3,4]],[[1,2],[3,4]]])\n",
    "    fc = FullyConnectedLayer(img.shape, 2)\n",
    "    out = fc.forward_propagate(img)\n",
    "    fc.backward_propagate(np.array([[1, -2],[3,4]]))\n",
    "    print(img.shape,out.shape,fc.w_grad.shape,fc.bias.shape)\n",
    "    print(out)\n",
    "    print(fc.w_grad)\n",
    "    print(fc.b_grad)\n",
    "    print(fc.weights)\n",
    "    print(fc.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 2, 5)\n",
      "(2, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# dot无效 matmul有效\n",
    "a = np.ones([2,3,4])\n",
    "b = np.ones([2,4,5])\n",
    "print(a.dot(b).shape)\n",
    "print(np.matmul(a,b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
