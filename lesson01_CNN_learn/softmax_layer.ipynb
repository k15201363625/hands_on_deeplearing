{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hands-on implementation of cnn with numpy--------softmax_loss layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax\n",
    "$$\\sigma_{i}(z)=\\frac{exp(z_{i})}{\\sum_{j=1}^m exp(z_{j})} , i=1,...,m$$\n",
    "## goal function (loss function)\n",
    "cross entropy(衡量两个分布响度) \n",
    "这里\n",
    "$$ - cross\\_entropy(pred,target) == -log\\_likelihood(\\sigma_{y}(z)) $$\n",
    "\n",
    "$$ log\\_likelyhood:log(\\sigma_{y}(z))=log(\\frac{exp(z_{y})}{\\sum_{j=1}^m exp(z_{j})}) = z_{y}-log(\\sum_{j=1}^m{e^{z_j}}) $$\n",
    "## 反向传播\n",
    "softmax没有参数的，所以我们只需要计算$\\frac{\\partial loss}{\\partial z}$即可。\n",
    "$$loss=-log\\_likelyhood = log(\\sum_{j=1}^m{e^{z_j}}) - z_{y} $$\n",
    "$$\\frac{\\partial loss}{\\partial z_k} = \\frac{exp(z_{k})}{\\sum_{j=1}^m exp(z_{j})} - \\delta_{ky} = \\sigma_{k}(z)-\\delta_{ky}, \\delta_{ky}= \\begin{cases} 0& \\text{y!=k}\\\\ 1& \\text{y=k} \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(object):\n",
    "    def __init__(self,shape):\n",
    "        self.input_shape = np.zeros(shape)\n",
    "        self.batch_size = shape[0]\n",
    "        # loss 对于 z求偏导\n",
    "        self.delta = np.zeros(shape)\n",
    "    def cal_loss(self,pred,target):\n",
    "        self.target = target\n",
    "        self.pred = pred\n",
    "        self.loss = 0\n",
    "        for i in range(self.batch_size):\n",
    "            self.loss += np.log(np.sum(np.exp(pred[i])))\n",
    "            self.loss -= pred[i,target[i]]\n",
    "            \n",
    "        self.forward_propagate(pred)\n",
    "        return self.loss\n",
    "    \n",
    "    def forward_propagate(self,pred):\n",
    "        self.prob = np.zeros(pred.shape)\n",
    "        for i in range(self.batch_size):\n",
    "            # 防止运算溢出\n",
    "            pred[i,:] -= np.max(pred[i,:])\n",
    "            softmax_prob = np.exp(pred[i]) / np.sum(np.exp(pred[i]))\n",
    "            self.prob[i] = softmax_prob\n",
    "        return self.prob\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"must be called after forward/cal_loss\"\"\"\n",
    "        return np.argmax(self.prob,axis=1)\n",
    "    \n",
    "    def backward_propagate(self):\n",
    "        self.delta = self.prob.copy()\n",
    "        for i in range(self.batch_size):\n",
    "            self.delta[i,self.target[i]] -= 1\n",
    "        return self.delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6253721511650081 [3 1]\n",
      "[[ 0.01521943  0.0413707   0.11245721 -0.16904734]\n",
      " [ 0.23688282 -0.35608574  0.0320586   0.08714432]]\n"
     ]
    }
   ],
   "source": [
    "# test code\n",
    "a = np.array([[1,2,3,5],[4,5,2,3]])\n",
    "mysoftmax = Softmax(a.shape)\n",
    "loss = mysoftmax.cal_loss(a,[3,1])\n",
    "pred = mysoftmax.predict()\n",
    "print(loss,pred)\n",
    "delta = mysoftmax.backward_propagate()\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo code\n",
    "np.argmax([[1,2,3,5],[4,5,2,3]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
